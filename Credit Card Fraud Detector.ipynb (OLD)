{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit Card Fraud Detector - by Alex Borger\n",
    "\n",
    "Inspired by the work of Andrea Dal Pozzolo\n",
    "\n",
    "Data by Worldline and the Machine Learning Group of the Free University of Brussels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we need to download the data from GitHub.  Alternatively, the data is publicly available from the following source:\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139639.0</td>\n",
       "      <td>-3.695745</td>\n",
       "      <td>3.452276</td>\n",
       "      <td>-4.440829</td>\n",
       "      <td>-1.347572</td>\n",
       "      <td>1.397759</td>\n",
       "      <td>3.891261</td>\n",
       "      <td>-2.915678</td>\n",
       "      <td>-2.237171</td>\n",
       "      <td>-0.065227</td>\n",
       "      <td>...</td>\n",
       "      <td>5.147840</td>\n",
       "      <td>-0.710243</td>\n",
       "      <td>0.827008</td>\n",
       "      <td>0.533215</td>\n",
       "      <td>-0.216667</td>\n",
       "      <td>-0.202473</td>\n",
       "      <td>-1.361741</td>\n",
       "      <td>-0.369330</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139639.0</td>\n",
       "      <td>2.139768</td>\n",
       "      <td>-0.802227</td>\n",
       "      <td>-1.436458</td>\n",
       "      <td>-0.874405</td>\n",
       "      <td>-0.426319</td>\n",
       "      <td>-0.098918</td>\n",
       "      <td>-1.115957</td>\n",
       "      <td>0.157473</td>\n",
       "      <td>-0.020360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239430</td>\n",
       "      <td>0.661485</td>\n",
       "      <td>0.072373</td>\n",
       "      <td>0.067434</td>\n",
       "      <td>-0.124332</td>\n",
       "      <td>-0.105274</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>-0.021729</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139640.0</td>\n",
       "      <td>2.045445</td>\n",
       "      <td>-1.735290</td>\n",
       "      <td>-1.005453</td>\n",
       "      <td>-1.593744</td>\n",
       "      <td>-1.227475</td>\n",
       "      <td>-0.183185</td>\n",
       "      <td>-1.106807</td>\n",
       "      <td>-0.038946</td>\n",
       "      <td>-1.449455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077245</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>0.203757</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>-0.307420</td>\n",
       "      <td>-0.262901</td>\n",
       "      <td>-0.009653</td>\n",
       "      <td>-0.033330</td>\n",
       "      <td>119.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139640.0</td>\n",
       "      <td>2.021652</td>\n",
       "      <td>-0.564466</td>\n",
       "      <td>-1.496431</td>\n",
       "      <td>0.688902</td>\n",
       "      <td>-0.375890</td>\n",
       "      <td>-1.128125</td>\n",
       "      <td>0.074404</td>\n",
       "      <td>-0.336272</td>\n",
       "      <td>-0.672393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232206</td>\n",
       "      <td>-0.256491</td>\n",
       "      <td>0.081733</td>\n",
       "      <td>-0.100709</td>\n",
       "      <td>0.147291</td>\n",
       "      <td>-0.515136</td>\n",
       "      <td>-0.003192</td>\n",
       "      <td>-0.044367</td>\n",
       "      <td>67.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139640.0</td>\n",
       "      <td>0.084695</td>\n",
       "      <td>-0.459907</td>\n",
       "      <td>0.451158</td>\n",
       "      <td>-2.774866</td>\n",
       "      <td>-1.002298</td>\n",
       "      <td>0.150489</td>\n",
       "      <td>-1.666675</td>\n",
       "      <td>-2.696009</td>\n",
       "      <td>-2.363629</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.385050</td>\n",
       "      <td>0.386718</td>\n",
       "      <td>-0.156815</td>\n",
       "      <td>-0.342012</td>\n",
       "      <td>0.791022</td>\n",
       "      <td>-0.197818</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.241003</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  139639.0 -3.695745  3.452276 -4.440829 -1.347572  1.397759  3.891261   \n",
       "1  139639.0  2.139768 -0.802227 -1.436458 -0.874405 -0.426319 -0.098918   \n",
       "2  139640.0  2.045445 -1.735290 -1.005453 -1.593744 -1.227475 -0.183185   \n",
       "3  139640.0  2.021652 -0.564466 -1.496431  0.688902 -0.375890 -1.128125   \n",
       "4  139640.0  0.084695 -0.459907  0.451158 -2.774866 -1.002298  0.150489   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0 -2.915678 -2.237171 -0.065227  ...  5.147840 -0.710243  0.827008  0.533215   \n",
       "1 -1.115957  0.157473 -0.020360  ...  0.239430  0.661485  0.072373  0.067434   \n",
       "2 -1.106807 -0.038946 -1.449455  ... -0.077245 -0.000323  0.203757  0.685393   \n",
       "3  0.074404 -0.336272 -0.672393  ... -0.232206 -0.256491  0.081733 -0.100709   \n",
       "4 -1.666675 -2.696009 -2.363629  ... -1.385050  0.386718 -0.156815 -0.342012   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.216667 -0.202473 -1.361741 -0.369330    5.50      0  \n",
       "1 -0.124332 -0.105274  0.012785 -0.021729   19.99      0  \n",
       "2 -0.307420 -0.262901 -0.009653 -0.033330  119.85      0  \n",
       "3  0.147291 -0.515136 -0.003192 -0.044367   67.64      0  \n",
       "4  0.791022 -0.197818  0.092000  0.241003   38.00      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/AlexBorger/DataProjects/master/creditcard{num}.csv'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    df = pd.concat([df,pd.read_csv(url.format(num=i))],ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data provided has already been sanitized and reduced into 28 principal components, a time field, a transaction amount (presumably in euros) and Class: 1 for fraudulent, 0 for genuine.  The transactions occurred over a few days in September 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n",
      "       Time        V5       V10       V15       V20       V25  Class\n",
      "0  139639.0  1.397759 -0.697197  0.910849 -1.653601 -0.216667      0\n",
      "1  139639.0 -0.426319  0.274247 -0.177653  0.027826 -0.124332      0\n",
      "2  139640.0 -1.227475  1.671403 -0.782821 -0.196871 -0.307420      0\n",
      "3  139640.0 -0.375890  1.132728  0.167542 -0.669641  0.147291      0\n",
      "4  139640.0 -1.002298  0.302008 -1.569565  0.332171  0.791022      0\n",
      "                Time            V1            V2            V3            V4  \\\n",
      "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean    94813.859575  4.228189e-15 -4.723485e-16 -1.097996e-14  2.688404e-15   \n",
      "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
      "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
      "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
      "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
      "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
      "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   4.185776e-15  1.499721e-15 -8.224755e-16 -6.141815e-16 -2.811419e-15   \n",
      "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
      "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
      "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
      "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
      "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
      "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   ...  9.424219e-17  4.431819e-16 -2.320318e-17  4.508821e-15   \n",
      "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
      "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
      "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
      "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
      "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
      "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
      "mean   6.769732e-16  1.566446e-15 -3.807437e-16 -1.108296e-16      88.349619   \n",
      "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
      "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
      "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
      "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
      "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
      "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
      "\n",
      "               Class  \n",
      "count  284807.000000  \n",
      "mean        0.001727  \n",
      "std         0.041527  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Basic descriptive stats:\n",
    "print(df.columns)\n",
    "print(df.iloc[:5,::5])\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 284807 rows\n",
      "           Time\n",
      "Class          \n",
      "0      284315.0\n",
      "1         492.0\n",
      "\n",
      " Fraudulent charges are only 0.17% of the examples.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(df.Time, df.Amount)\n",
    "plt.show()\n",
    "print('Length of dataset: {l} rows'.format(l=len(df)))\n",
    "print(df.groupby('Class').agg({'Time':len}))\n",
    "print('\\n Fraudulent charges are only {p}% of the examples.'.format(p=round(100*sum(df['Class'])/len(df),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the dataset is highly unbalanced.  There are 578 genuine transactions per fraudulent transaction in the dataset.  As such, we will need to manage the difference in class support with any model we use.  There is no proven way to best mitigate this issue.  This notebook will highlight the final selected methods of creating a predictive model.  The main methods that follow are weight balancing the entire training set and using a decision tree on a balanced, undersampled dataset.\n",
    "\n",
    "Before we begin, we should make sure that our principal components are valid.  If they are valid, the principal component analysis output of these 28 columns should yield vectors pointing directly along all 28 axes (thus indicating the top 28 vectors (in n-dim space) are the axes themselves), and they should be in order.  Such a result would look (within a small tolerance) like a 28x28 identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\n",
      "[3.8365 2.7268 2.299  2.0047 1.9051 1.7749 1.5304 1.4265 1.207  1.1856\n",
      " 1.0419 0.9984 0.9906 0.9189 0.8378 0.7678 0.7214 0.7025 0.6627 0.5943\n",
      " 0.5395 0.5266 0.39   0.3668 0.2717 0.2325 0.1629 0.109 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to prove that V1 through V28 are principal components?\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "cols = df.columns[1:29]\n",
    "pca = PCA(n_components=28)\n",
    "pca.fit(df[cols])\n",
    "\n",
    "# We need to verify that the principal components are, in fact, the 28 features provided.\n",
    "# This will be evident if the results of PCA fitting point solely in the direction of each feature's axis.\n",
    "\n",
    "for i in range(len(pca.components_)):\n",
    "    if abs(np.round(pca.components_[i][i],14))!=1:\n",
    "        print('Impure component found')\n",
    "    else:\n",
    "        print('.',end='')\n",
    "        \n",
    "# Furthermore, the explained variance of each component should already be in sorted order - but we will verify that this is the case.\n",
    "print('\\n'+str(np.round(pca.explained_variance_,4)))\n",
    "\n",
    "# It is clear that they are in order from visual inspection, but if we are to accept more data in the future, we should be able to verify this\n",
    "# in the ETL pipeline.\n",
    "\n",
    "ev = pca.explained_variance_\n",
    "delta = ev[:-1] - ev[1:] # This will subtract the next element from each element, except the last\n",
    "np.all(delta == abs(delta)) # This will verify if every element in the delta array is monotonically decreasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a number of helper functions.  Some of them are used in the final models but others have been preserved to act solely as references.\n",
    "\n",
    "standardize_data - Uses sklearn's StandardScaler to map data to its standard deviation (within column).\n",
    "\n",
    "split_data - Randomly splits a dataframe into train and test features and output labels.\n",
    "\n",
    "oversample - For a binary classification task only -- this will determine which class has a smaller support (fewer examples) and randomly sample and append repeating data to the dataframe until both classes are balanced (upsampling)\n",
    "\n",
    "undersample - A broader classification implementation -- this will find the support of N classes and randomly sample from all classes, returning a balanced dataframe with the support of the least frequent class (downsampling)\n",
    "\n",
    "We will not need the oversample method.  The other three will be used to represent our two final implementations:\n",
    "\n",
    "Weighted binary classification feed forward Neural Network and random decision tree (undersampled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 227846\n",
      "Test examples: 56961\n"
     ]
    }
   ],
   "source": [
    "# Option A:\n",
    "\n",
    "# Send the existing data to a FF NN without any normalization or oversampling of fraudulent records\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def standardize_data(df, avoid_cols = ['Class']):\n",
    "    scaler = StandardScaler()\n",
    "    for c in df.columns:\n",
    "        if c in avoid_cols:\n",
    "            pass\n",
    "        else:\n",
    "            #df[c] = normalize(scaler.fit_transform(df[[c]]))\n",
    "            df[c] = scaler.fit_transform(df[[c]])\n",
    "            \n",
    "    return df\n",
    "\n",
    "def split_data(df, split_frac):\n",
    "    \n",
    "    # This function assumes frequency of positive and negative examples are balanced.\n",
    "    #print('df')\n",
    "    #print(df.describe())\n",
    "    \n",
    "    df = shuffle(df)\n",
    "    ind = round(len(df)*split_frac)\n",
    "    train_x = df[:ind]\n",
    "    test_x = df[ind:]\n",
    "    #print('train_x')\n",
    "    #print(train_x.describe())\n",
    "    #print('test_x')\n",
    "    #print(test_x.describe())\n",
    "    \n",
    "    train_y = train_x.pop('Class')\n",
    "    test_y = test_x.pop('Class')\n",
    "    \n",
    "    print('Training examples: {0}'.format(len(train_x)))\n",
    "    print('Test examples: {0}'.format(len(test_x)))\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "# Let's oversample!\n",
    "\n",
    "def oversample(df, label_col = 'Class'):\n",
    "    \n",
    "    # For now, we assume binary classification.\n",
    "    \n",
    "    falses = df[df[label_col]==0]\n",
    "    positives = df[df[label_col]==1]\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    if len(falses)==len(positives):\n",
    "        print('they are the same')\n",
    "        return df\n",
    "    elif len(falses)<len(positives):\n",
    "        print('falses are shorter')\n",
    "        while len(falses)<len(positives):\n",
    "            delta = len(positives) - len(falses)\n",
    "            if delta < len(falses):\n",
    "                falses = falses.append(falses.sample(delta))\n",
    "            else:\n",
    "                falses = falses.append(falses)\n",
    "            counter += 1\n",
    "            if counter % 10 == 0:\n",
    "                print('.', end = '')\n",
    "    else:\n",
    "        print('positives are shorter')\n",
    "        while len(positives)<len(falses):\n",
    "            delta = len(falses)-len(positives)\n",
    "            if delta < len(positives):\n",
    "                positives = positives.append(positives.sample(delta))\n",
    "            else:\n",
    "                positives = positives.append(positives)\n",
    "            counter += 1\n",
    "            if counter % 10 == 0:\n",
    "                print('.', end = '')\n",
    "    print('')\n",
    "    print(len(falses))\n",
    "    print(len(positives))\n",
    "    df = positives.append(falses)\n",
    "    return df\n",
    "\n",
    "# Undersampling\n",
    "\n",
    "def undersample(df, label_col = 'Class'):\n",
    "    supports = dict()\n",
    "    classes = list(set(df[label_col]))\n",
    "    classes.sort()\n",
    "    for class_val in classes:\n",
    "        supports[class_val] = len(df[df[label_col]==class_val])\n",
    "        \n",
    "    # Obtain the support size of the smallest class\n",
    "    target = len(df)\n",
    "    for class_val in supports:\n",
    "        if supports[class_val] < target:\n",
    "            target = supports[class_val]\n",
    "    \n",
    "    # Reduce each class to the target value with the df.sample() method\n",
    "    class_results = []\n",
    "    for cl in classes:\n",
    "        #print(df[df[label_col]==cl].iloc[0])\n",
    "        class_results.append(df[df[label_col]==cl].sample(target))\n",
    "    \n",
    "    return pd.concat(class_results,ignore_index=True)\n",
    "\n",
    "\n",
    "# You can swap out df_u for df_o to see the results of training on the oversampled dataset.\n",
    "\n",
    "df_s = standardize_data(df)\n",
    "#df_o = oversample(df_s)\n",
    "df_u = undersample(df_s)\n",
    "#print(df_u)\n",
    "#train_x, train_y, test_x, test_y = split_data(df_u, 0.8)\n",
    "train_x, train_y, test_x, test_y = split_data(df_s, 0.8)\n",
    "\n",
    "\n",
    "# It is highly recommended to split your data BEFORE oversampling the training data, since your model will otherwise be able to see\n",
    "# the same records in both sets and give the correct answer by memory.  This is not implemented here, since undersampling is the\n",
    "# generally preferred method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feed forward model definition follows below.  I am using a 3 hidden layer (128, 128, 64) fully connected feed forward NN.  The hidden activations are ReLU (Rectified Linear Units) and the final activation is the sigmoid function (maps all real numbers from 0 to 1, perfect for binary classification).  The output unit undergoing the sigmoid activation is one unit between 0 and 1 and acts as the prediction for a given example.\n",
    "\n",
    "To compensate for the unbalanced nature of this dataset, we will be using a weighted loss function:\n",
    "\n",
    "$\\sum -\\alpha \\mathbf{y}\\log\\left (\\boldsymbol{\\hat{y}}  \\right ) - \\beta \\mathbf{\\left ( \\ 1-y \\right )}\\log\\left (\\boldsymbol{1-\\hat{y}}  \\right )$\n",
    "\n",
    "For the sake of ease, we will allow beta to be 1 and adjust alpha accordingly.  We can use sklearn's compute_class_weight function to return class weights (typically a list [class 0 val, class 1 val]).  These are akin to alpha and beta respectively, so we will pass to tensorflow's weighted_cross_entropy_with_logits function a pos_weight of $\\frac{\\alpha}{\\beta}$.\n",
    "\n",
    "I will be using stochastic gradient descent (SGD) as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.50086524 289.43800813]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>-0.001233</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.997694</td>\n",
       "      <td>0.996705</td>\n",
       "      <td>0.997582</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.997724</td>\n",
       "      <td>0.994102</td>\n",
       "      <td>1.000089</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003860</td>\n",
       "      <td>0.989791</td>\n",
       "      <td>0.998785</td>\n",
       "      <td>1.003040</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>1.000094</td>\n",
       "      <td>1.002318</td>\n",
       "      <td>1.001011</td>\n",
       "      <td>0.995273</td>\n",
       "      <td>1.008253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-28.798555</td>\n",
       "      <td>-44.035292</td>\n",
       "      <td>-31.871733</td>\n",
       "      <td>-4.013919</td>\n",
       "      <td>-82.408097</td>\n",
       "      <td>-19.636058</td>\n",
       "      <td>-35.209396</td>\n",
       "      <td>-61.302524</td>\n",
       "      <td>-12.228015</td>\n",
       "      <td>...</td>\n",
       "      <td>-70.691461</td>\n",
       "      <td>-47.419067</td>\n",
       "      <td>-15.065646</td>\n",
       "      <td>-71.754464</td>\n",
       "      <td>-4.683638</td>\n",
       "      <td>-19.750332</td>\n",
       "      <td>-5.401098</td>\n",
       "      <td>-55.906596</td>\n",
       "      <td>-46.746117</td>\n",
       "      <td>-0.353229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.855602</td>\n",
       "      <td>-0.469695</td>\n",
       "      <td>-0.362994</td>\n",
       "      <td>-0.587449</td>\n",
       "      <td>-0.598457</td>\n",
       "      <td>-0.502127</td>\n",
       "      <td>-0.576576</td>\n",
       "      <td>-0.446243</td>\n",
       "      <td>-0.174934</td>\n",
       "      <td>-0.586670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274527</td>\n",
       "      <td>-0.311500</td>\n",
       "      <td>-0.749256</td>\n",
       "      <td>-0.259379</td>\n",
       "      <td>-0.585590</td>\n",
       "      <td>-0.606983</td>\n",
       "      <td>-0.679367</td>\n",
       "      <td>-0.175839</td>\n",
       "      <td>-0.160715</td>\n",
       "      <td>-0.331120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.214114</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.117481</td>\n",
       "      <td>-0.013471</td>\n",
       "      <td>-0.039040</td>\n",
       "      <td>-0.206646</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>-0.047991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080899</td>\n",
       "      <td>-0.040319</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>-0.017865</td>\n",
       "      <td>0.067176</td>\n",
       "      <td>0.031419</td>\n",
       "      <td>-0.109542</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.033936</td>\n",
       "      <td>-0.265271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.935680</td>\n",
       "      <td>0.671640</td>\n",
       "      <td>0.486252</td>\n",
       "      <td>0.676697</td>\n",
       "      <td>0.524849</td>\n",
       "      <td>0.443920</td>\n",
       "      <td>0.298888</td>\n",
       "      <td>0.462106</td>\n",
       "      <td>0.272885</td>\n",
       "      <td>0.542377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172338</td>\n",
       "      <td>0.253723</td>\n",
       "      <td>0.728095</td>\n",
       "      <td>0.236612</td>\n",
       "      <td>0.725286</td>\n",
       "      <td>0.673335</td>\n",
       "      <td>0.500245</td>\n",
       "      <td>0.224792</td>\n",
       "      <td>0.236917</td>\n",
       "      <td>-0.043178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.641974</td>\n",
       "      <td>1.251799</td>\n",
       "      <td>13.357750</td>\n",
       "      <td>6.187993</td>\n",
       "      <td>11.918743</td>\n",
       "      <td>25.214135</td>\n",
       "      <td>55.020149</td>\n",
       "      <td>97.478239</td>\n",
       "      <td>16.751534</td>\n",
       "      <td>14.194945</td>\n",
       "      <td>...</td>\n",
       "      <td>51.134640</td>\n",
       "      <td>37.034714</td>\n",
       "      <td>14.473041</td>\n",
       "      <td>36.076675</td>\n",
       "      <td>7.569684</td>\n",
       "      <td>14.425318</td>\n",
       "      <td>7.293975</td>\n",
       "      <td>78.319397</td>\n",
       "      <td>102.543421</td>\n",
       "      <td>102.362243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  227846.000000  227846.000000  227846.000000  227846.000000   \n",
       "mean       -0.000714       0.000824      -0.000156      -0.000445   \n",
       "std         0.999790       0.997694       0.996705       0.997582   \n",
       "min        -1.996583     -28.798555     -44.035292     -31.871733   \n",
       "25%        -0.855602      -0.469695      -0.362994      -0.587449   \n",
       "50%        -0.214114       0.009446       0.039391       0.117481   \n",
       "75%         0.935680       0.671640       0.486252       0.676697   \n",
       "max         1.641974       1.251799      13.357750       6.187993   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  227846.000000  227846.000000  227846.000000  227846.000000   \n",
       "mean        0.000470      -0.000079       0.000035       0.002395   \n",
       "std         0.999849       0.999945       0.999545       0.997724   \n",
       "min        -4.013919     -82.408097     -19.636058     -35.209396   \n",
       "25%        -0.598457      -0.502127      -0.576576      -0.446243   \n",
       "50%        -0.013471      -0.039040      -0.206646       0.033389   \n",
       "75%         0.524849       0.443920       0.298888       0.462106   \n",
       "max        11.918743      25.214135      55.020149      97.478239   \n",
       "\n",
       "                  V8             V9  ...            V20            V21  \\\n",
       "count  227846.000000  227846.000000  ...  227846.000000  227846.000000   \n",
       "mean       -0.000426      -0.001007  ...       0.000205      -0.001233   \n",
       "std         0.994102       1.000089  ...       1.003860       0.989791   \n",
       "min       -61.302524     -12.228015  ...     -70.691461     -47.419067   \n",
       "25%        -0.174934      -0.586670  ...      -0.274527      -0.311500   \n",
       "50%         0.018608      -0.047991  ...      -0.080899      -0.040319   \n",
       "75%         0.272885       0.542377  ...       0.172338       0.253723   \n",
       "max        16.751534      14.194945  ...      51.134640      37.034714   \n",
       "\n",
       "                 V22            V23            V24            V25  \\\n",
       "count  227846.000000  227846.000000  227846.000000  227846.000000   \n",
       "mean       -0.001228       0.000148      -0.000493       0.000259   \n",
       "std         0.998785       1.003040       1.000859       1.000094   \n",
       "min       -15.065646     -71.754464      -4.683638     -19.750332   \n",
       "25%        -0.749256      -0.259379      -0.585590      -0.606983   \n",
       "50%         0.007107      -0.017865       0.067176       0.031419   \n",
       "75%         0.728095       0.236612       0.725286       0.673335   \n",
       "max        14.473041      36.076675       7.569684      14.425318   \n",
       "\n",
       "                 V26            V27            V28         Amount  \n",
       "count  227846.000000  227846.000000  227846.000000  227846.000000  \n",
       "mean       -0.000135       0.000488       0.000220       0.001329  \n",
       "std         1.002318       1.001011       0.995273       1.008253  \n",
       "min        -5.401098     -55.906596     -46.746117      -0.353229  \n",
       "25%        -0.679367      -0.175839      -0.160715      -0.331120  \n",
       "50%        -0.109542       0.003309       0.033936      -0.265271  \n",
       "75%         0.500245       0.224792       0.236917      -0.043178  \n",
       "max         7.293975      78.319397     102.543421     102.362243  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow import nn\n",
    "from sklearn import utils as sku\n",
    "\n",
    "weights = sku.class_weight.compute_class_weight('balanced',np.unique(df_s['Class']), df_s['Class'])\n",
    "print(weights)\n",
    "\n",
    "def weighted_loss(y_true,y_pred):\n",
    "        return nn.weighted_cross_entropy_with_logits(y_true,y_pred,weights[1]/weights[0])\n",
    "\n",
    "#def weighted_loss(y_true, y_pred):\n",
    "#    print(y_pred)\n",
    "#    return K.sum(-5*y_true*K.log(y_pred.map(lambda x: max(0.01,x))) - (1-y_true)*K.log(K.max(1-y_pred,0.01)))\n",
    "    \n",
    "\n",
    "def get_model(df):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=len(df.columns), init=\"glorot_normal\", activation=\"relu\")) # glorot_normal is the Xavier initializer - avoids 0 weights\n",
    "    model.add(Dense(128, activation=\"relu\", kernel_initializer=\"glorot_normal\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation=\"relu\", kernel_initializer=\"glorot_normal\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, x, y, val_split = 0.1, epochs = 5, batch_size = 128, verbose = 1):\n",
    "    \n",
    "\n",
    "    # train the model using SGD\n",
    "    sgd = SGD(lr=0.01)\n",
    "    #model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"]) # normal -- works fine\n",
    "    #model.compile(loss=weighted_loss, optimizer=sgd, metrics=[\"accuracy\"]) # \n",
    "    model.compile(loss=weighted_loss, optimizer=sgd, metrics=[\"accuracy\"]) # \n",
    "    #model.compile(loss=nn.weighted_cross_entropy_with_logits(pos_weight=100), optimizer=sgd, metrics=[\"accuracy\"]) # \n",
    "    \n",
    "    history = model.fit(x, y, validation_split = val_split, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "train_x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function get_report.  With a model's final weights, a log of metrics during training and test data, this function will present multiple valuable model performance indicators, including:\n",
    "\n",
    "Accuracy - the total fraction of correct predictions in the test set (assuming a threshold of 50% likelihood)\n",
    "\n",
    "Precision - the total fraction of positive predictions that are true positives (how many fraud detections were fraud)\n",
    "\n",
    "Recall - the total fraction of true positives that were positive predictions (how many frauds did we properly detect)\n",
    "\n",
    "F1 score - calculated as \n",
    "\n",
    "$2 * \\frac{\\boldsymbol{P*R}}{\\boldsymbol{P+R}}$\n",
    "\n",
    "where P is precision and R is recall.\n",
    "\n",
    "Confusion matrix:\n",
    "\n",
    "$\\begin{vmatrix}\n",
    "TN & FP\\\\ \n",
    "FN & TP\n",
    "\\end{vmatrix}$\n",
    "\n",
    "T - True, F - False, N - Negative, P - Positive\n",
    "\n",
    "Given the nature of our task, we would like to reduce False Negatives as much as possible, since every FN costs the bank dearly (cost of transaction, labor and potential customer churn).  It can be assumed that the cost of a False Positive is considerably less than that of a FN.  As a result, we will use recall as our primary model performance indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "\n",
    "def get_report(model, history, test_x, test_y):\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Losses')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Cross Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_x, test_y)\n",
    "    \n",
    "    # predict probabilities for test set\n",
    "    yhat_probs = model.predict(test_x, verbose=0)\n",
    "    # predict crisp classes for test set\n",
    "    yhat_classes = model.predict_classes(test_x, verbose=0)\n",
    "    # reduce to 1d array\n",
    "    yhat_probs = yhat_probs[:, 0]\n",
    "    yhat_classes = yhat_classes[:, 0]\n",
    "     \n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = skm.accuracy_score(test_y, yhat_classes)\n",
    "    print('Accuracy: {0}'.format(accuracy))\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = skm.precision_score(test_y, yhat_classes)\n",
    "    print('Precision: {0}'.format(precision))\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = skm.recall_score(test_y, yhat_classes)\n",
    "    print('Recall: {0}'.format(recall))\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = skm.f1_score(test_y, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    " \n",
    "    # ROC AUC\n",
    "    #auc = skm.roc_auc_score(test_y, yhat_probs)\n",
    "    #print('ROC AUC: %f' % auc)\n",
    "    \n",
    "    # AUPRC\n",
    "    precision, recall, thresh = skm.precision_recall_curve(test_y, yhat_probs)\n",
    "    #print('AUPRC: precision: {p}\\n recall: {r}\\n threshold: {t}'.format(p=precision,r=recall,t=thresh))\n",
    "    plt.figure()\n",
    "    plt.plot(thresh, precision[:-1])\n",
    "    plt.plot(thresh, recall[:-1])\n",
    "    plt.legend(['Precision','Recall'])\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # confusion matrix\n",
    "    matrix = skm.confusion_matrix(test_y, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    print('The highest fraud likelihood measured was {0}.'.format(max(yhat_probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined our model, let's fit our model on our standardized training data.  We'll use a batch size of 64 examples (speeding up the calculations through the layers of the network by using vectorized formulas).  We'll also run this through our training set 40 times.\n",
    "\n",
    "Note:  If your computer is taking a while to compute these calculations, feel free to change the batch_size value to 128 or 256 and decrease the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, input_dim=30, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               3968      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,801\n",
      "Trainable params: 28,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 205061 samples, validate on 22785 samples\n",
      "Epoch 1/40\n",
      "205061/205061 [==============================] - 4s 18us/step - loss: 1.0940 - accuracy: 0.9751 - val_loss: 1.0618 - val_accuracy: 0.9813\n",
      "Epoch 2/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0640 - accuracy: 0.9861 - val_loss: 1.0594 - val_accuracy: 0.9899\n",
      "Epoch 3/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0578 - accuracy: 0.9843 - val_loss: 1.0584 - val_accuracy: 0.9928\n",
      "Epoch 4/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0559 - accuracy: 0.9877 - val_loss: 1.0570 - val_accuracy: 0.9920\n",
      "Epoch 5/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0540 - accuracy: 0.9868 - val_loss: 1.0582 - val_accuracy: 0.9877\n",
      "Epoch 6/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0498 - accuracy: 0.9895 - val_loss: 1.0579 - val_accuracy: 0.9932\n",
      "Epoch 7/40\n",
      "205061/205061 [==============================] - 4s 18us/step - loss: 1.0515 - accuracy: 0.9830 - val_loss: 1.0680 - val_accuracy: 0.9634\n",
      "Epoch 8/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0520 - accuracy: 0.9825 - val_loss: 1.0583 - val_accuracy: 0.9920\n",
      "Epoch 9/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0479 - accuracy: 0.9885 - val_loss: 1.0640 - val_accuracy: 0.9829\n",
      "Epoch 10/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0474 - accuracy: 0.9875 - val_loss: 1.0550 - val_accuracy: 0.9793\n",
      "Epoch 11/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0472 - accuracy: 0.9882 - val_loss: 1.0624 - val_accuracy: 0.9887\n",
      "Epoch 12/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0492 - accuracy: 0.9836 - val_loss: 1.0627 - val_accuracy: 0.9763\n",
      "Epoch 13/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0451 - accuracy: 0.9866 - val_loss: 1.0625 - val_accuracy: 0.9914\n",
      "Epoch 14/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0420 - accuracy: 0.9909 - val_loss: 1.0612 - val_accuracy: 0.9914\n",
      "Epoch 15/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0449 - accuracy: 0.9897 - val_loss: 1.0648 - val_accuracy: 0.9893\n",
      "Epoch 16/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0427 - accuracy: 0.9911 - val_loss: 1.0575 - val_accuracy: 0.9939\n",
      "Epoch 17/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0412 - accuracy: 0.9934 - val_loss: 1.0658 - val_accuracy: 0.9675\n",
      "Epoch 18/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0440 - accuracy: 0.9858 - val_loss: 1.0673 - val_accuracy: 0.9914\n",
      "Epoch 19/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0445 - accuracy: 0.9847 - val_loss: 1.0606 - val_accuracy: 0.9876\n",
      "Epoch 20/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0417 - accuracy: 0.9918 - val_loss: 1.0584 - val_accuracy: 0.9913\n",
      "Epoch 21/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0394 - accuracy: 0.9938 - val_loss: 1.0651 - val_accuracy: 0.9958\n",
      "Epoch 22/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0389 - accuracy: 0.9948 - val_loss: 1.0650 - val_accuracy: 0.9960\n",
      "Epoch 23/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0383 - accuracy: 0.9959 - val_loss: 1.0594 - val_accuracy: 0.9896\n",
      "Epoch 24/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0389 - accuracy: 0.9938 - val_loss: 1.0589 - val_accuracy: 0.9969\n",
      "Epoch 25/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0388 - accuracy: 0.9941 - val_loss: 1.0523 - val_accuracy: 0.9920\n",
      "Epoch 26/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0413 - accuracy: 0.9928 - val_loss: 1.0538 - val_accuracy: 0.9931\n",
      "Epoch 27/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0388 - accuracy: 0.9944 - val_loss: 1.0649 - val_accuracy: 0.9968\n",
      "Epoch 28/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0385 - accuracy: 0.9949 - val_loss: 1.0656 - val_accuracy: 0.9969\n",
      "Epoch 29/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0382 - accuracy: 0.9952 - val_loss: 1.0676 - val_accuracy: 0.9975\n",
      "Epoch 30/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0394 - accuracy: 0.9928 - val_loss: 1.0552 - val_accuracy: 0.9971\n",
      "Epoch 31/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0395 - accuracy: 0.9950 - val_loss: 1.0559 - val_accuracy: 0.9957\n",
      "Epoch 32/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0402 - accuracy: 0.9926 - val_loss: 1.0572 - val_accuracy: 0.9961\n",
      "Epoch 33/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0383 - accuracy: 0.9951 - val_loss: 1.0646 - val_accuracy: 0.9967\n",
      "Epoch 34/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0370 - accuracy: 0.9968 - val_loss: 1.0616 - val_accuracy: 0.9964\n",
      "Epoch 35/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0369 - accuracy: 0.9967 - val_loss: 1.0645 - val_accuracy: 0.9977\n",
      "Epoch 36/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0381 - accuracy: 0.9959 - val_loss: 1.0645 - val_accuracy: 0.9972\n",
      "Epoch 37/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0405 - accuracy: 0.9919 - val_loss: 1.0564 - val_accuracy: 0.9949\n",
      "Epoch 38/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0379 - accuracy: 0.9951 - val_loss: 1.0555 - val_accuracy: 0.9965\n",
      "Epoch 39/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0373 - accuracy: 0.9962 - val_loss: 1.0576 - val_accuracy: 0.9977\n",
      "Epoch 40/40\n",
      "205061/205061 [==============================] - 4s 17us/step - loss: 1.0379 - accuracy: 0.9960 - val_loss: 1.0624 - val_accuracy: 0.9968\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56961/56961 [==============================] - 1s 10us/step\n",
      "Accuracy: 0.9963483787152613\n",
      "Precision: 0.2872727272727273\n",
      "Recall: 0.8681318681318682\n",
      "F1 score: 0.431694\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcXFWd9/HPr6uX6j1Jd2ftbEBWQjYaSIwKCsGAGB4ZECKuw4gDQ5gRHcVhFMbR5xHEZdD4YGQkuLGo83JQw4DIEs1DIEHClp0spJOQdLZO793V/Xv+qOpKp9Od7iR9q7q6vu/Xq151b91T9/5OB+6v7jnnnmvujoiICEBGsgMQEZH+Q0lBRETilBRERCROSUFEROKUFEREJE5JQURE4pQUREQkTklBRETilBRERCQuM9kBnKzS0lIfN25cssMQEUkpL7/88n53L+upXMolhXHjxrFmzZpkhyEiklLMbEdvyqn5SERE4pQUREQkTklBRETiUq5PQUQGtpaWFiorK2lsbEx2KCkpHA5TXl5OVlbWKX1fSUFE+pXKykoKCwsZN24cZpbscFKKu3PgwAEqKysZP378Ke0jsOYjM/uJme0zsze62W5mdp+ZbTGz18xsdlCxiEjqaGxspKSkRAnhFJgZJSUlp3WVFWSfwjJgwQm2XwZMiL1uBP5vgLGISApRQjh1p/u3CywpuPsK4OAJilwJ/NSjVgGDzGxEUPGw4wV45hsQaQ7sECIiqS6Zo49GATs7rFfGPjuOmd1oZmvMbE1VVdWpHa3yJVhxD7S1nNr3RSRthEIhZs6cybRp07jmmmuor68/7X2uWbOGW2+9tdvtu3fv5uqrrz7t45yuZCaFrq5xvKuC7r7U3SvcvaKsrMe7tE98OG87xe+LSLrIzc1l7dq1vPHGG2RnZ3P//fcfs93daWs7uXNJRUUF9913X7fbR44cya9//etTircvJTMpVAKjO6yXA7sDO5rFqqqkICIn4T3veQ9btmxh+/btTJkyhZtvvpnZs2ezc+dOnnrqKebOncvs2bO55pprqK2tBWD16tW8613vYsaMGZx//vnU1NTw3HPPccUVVwDw/PPPM3PmTGbOnMmsWbOoqalh+/btTJs2DYh2tn/605/mnHPOYdasWTz77LMALFu2jKuuuooFCxYwYcIEvvjFL/Z5fZM5JPVx4BYzewS4AKh29z2BHS2eFLq8GBGRfujffvcm63Yf6dN9Th1ZxJ0fOrtXZSORCE888QQLFkTHzGzcuJEHH3yQH/7wh+zfv5+vf/3rPP300+Tn53P33Xfzne98h9tvv51rr72WRx99lPPOO48jR46Qm5t7zH7vvfdelixZwrx586itrSUcDh+zfcmSJQC8/vrrbNiwgUsvvZRNmzYBsHbtWl555RVycnKYNGkSixcvZvTo0fSVwJKCmT0MXASUmlklcCeQBeDu9wPLgcuBLUA98OmgYokFFH3XlYKI9KChoYGZM2cC0SuFG264gd27dzN27FjmzJkDwKpVq1i3bh3z5s0DoLm5mblz57Jx40ZGjBjBeeedB0BRUdFx+583bx633XYb119/PVdddRXl5eXHbP/LX/7C4sWLAZg8eTJjx46NJ4WLL76Y4uJiAKZOncqOHTtSIym4+6IetjvwD0Ed/zimGT1EUk1vf9H3tfY+hc7y8/Pjy+7O/Pnzefjhh48p89prr/U4LPT222/ngx/8IMuXL2fOnDk8/fTTx1wt+AlaNHJycuLLoVCISCTSY31ORhqdKXWlICJ9Z86cOaxcuZItW7YAUF9fz6ZNm5g8eTK7d+9m9erVANTU1Bx34n7rrbc455xz+NKXvkRFRQUbNmw4Zvt73/tefvGLXwCwadMm3n77bSZNmpSAWqVTUlDzkYj0obKyMpYtW8aiRYuYPn06c+bMYcOGDWRnZ/Poo4+yePFiZsyYwfz584+7w/h73/se06ZNY8aMGeTm5nLZZZcds/3mm2+mtbWVc845h2uvvZZly5Ydc4UQJDvRZUp/VFFR4af0kJ3V/wl/uA0+vwkKh/V9YCLSJ9avX8+UKVOSHUZK6+pvaGYvu3tFT9/VlYKIiMSlUVJor2pqXRmJiCRS+iQFdTSLiPQofZKC7mgWEelRGiYFNR+JiHQnjZKCmo9ERHqSRklBHc0i0jsdp87+0Ic+xOHDh/t0/8uWLeOWW24B4K677uLee+/t0/2fjvRJCu0dzTV7oakmuaGISL/WcersIUOGxCeoSwfpkxQyY3cDPrgA7p2kxCAivTJ37lx27doVX//Wt77Feeedx/Tp07nzzjvjn//0pz9l+vTpzJgxg49//OMA/O53v+OCCy5g1qxZXHLJJezduzfh8Z+sZE6dnVgTPwD/637Y8Rd45edQuw9yCpMdlYicyBO3wzuv9+0+h58Dl32zV0VbW1v505/+xA033ADAU089xebNm3nppZdwdxYuXMiKFSsoKSnhG9/4BitXrqS0tJSDB6NPIn73u9/NqlWrMDMeeOAB7rnnHr797W/3bX36WPokhaxcmLkomghe+TksvQgyQgkMwOD9d8B5f5fAY4rIqWifOnv79u2ce+65zJ8/H4gmhaeeeopZs2YBUFtby+bNm3n11Ve5+uqrKS0tBWDIkCEAVFZWcu2117Jnzx6am5sZP358cip0EtInKbQb/16Y94/Q0pDY467/Paz/nZKCyMno5S/6vtbep1BdXc0VV1zBkiVLuPXWW3F3vvzlL/PZz372mPL33Xdfl9NlL168mNtuu42FCxfy3HPPcddddyWoBqcu/ZJCuAjmfy3xx21pgNd/BQ9+MPHHTjQzmHMTTE6DusqAVlxczH333ceVV17JTTfdxAc+8AG+8pWvcP3111NQUMCuXbvIysri4osv5sMf/jCf+9znKCkp4eDBgwwZMoTq6mpGjRoFwEMPPZTk2vRO+iWFZJn5UTi0PT1untv7Jvzle0oKMiDMmjWLGTNm8Mgjj/Dxj3+c9evXM3fuXAAKCgr4+c9/ztlnn80dd9zBhRdeSCgUYtasWSxbtoy77rqLa665hlGjRjFnzhy2bduW5Nr0LH2mzpbEee5ueO7/wHk3DOwn3lkGjHtPdBBDKCvZ0QwYmjr79J3O1Nm6UpC+N+1v4K8PwRu/SXYkwYo0w4v3Q/7Q6JXg7E9AyZnJjkrktCgpSN8rPQtuW5fsKILXGoEtf4S//hT+3/dh5fdg7LthyoeO3heTEYLJV0DekOTGKtJLSgoipyqUCZMui76O7IFXfxlNEP/zpWPLHdkDF32p631Il9y9y9E80rPT7RJQUhDpC0Uj4D2fh3mfg7p9RwcU/PAC2LcOdr7U8z5KJ0Du4GDjTAHhcJgDBw5QUlKixHCS3J0DBw4QDodPeR9KCiJ9KSMDCocfXS8cCet+G331JLsgOpR37i2QOyi4GPu58vJyKisrqaqqSnYoKSkcDlNeXn7K31dSEAnS9Y/B/k09l2uNwKsPw4pvwUtLYe5iqPjbo30TaSQLGD+yLNlh9C9ZuQmbgUFDUkX6kz2vRYfzblye7EikPxkxEz77/GntQkNSRVLRiOmw6GHY9TJsX5nsaKQ/2PkibPg91B9MyCg2JQWR/mjUudGXyFvPRJPCAxfD9b8O/F6YAXy7qYjIADB2XvR1cCvsWx/44ZQURET6s8wcuOye6LK3Bn44JQURkf6ufeRRW4onBTNbYGYbzWyLmd3exfYxZvasmb1iZq+Z2eVBxiMikpIslhS8LfBDBZYUzCwELAEuA6YCi8xsaqdi/wo85u6zgOuAHwYVj4hIyhogVwrnA1vcfau7NwOPAFd2KuNAUWy5GNgdYDwiIqmpfQr6BPQpBDkkdRSws8N6JXBBpzJ3AU+Z2WIgH7gkwHhERFLTALlS6Gomq863Ty8Clrl7OXA58DOz45/KYmY3mtkaM1uj+VBEJO3E+xRSOylUAqM7rJdzfPPQDcBjAO7+AhAGSjvvyN2XunuFu1eUlWlOFBFJMwPkSmE1MMHMxptZNtGO5Mc7lXkbuBjAzKYQTQq6FBAR6aAuo4Anp36TTQU9Tl102gJLCu4eAW4BngTWEx1l9KaZfc3MFsaKfR74jJm9CjwMfMpTbYY+EZGA1bVl8tm/juGl6uCnVA907iN3Xw4s7/TZVzssrwPmBRmDiEjKS+BPZd3RLCLSz7XnhEQ8iE5JQUQkRViXgzr7lpKCiEg/l8ieViUFEZF+zmMNSGo+EhGRuATkBCUFEZH+Ts1HIiISp9FHIiJyHI0+EhEREjnRg5KCiEg/F88Jaj4SEZF2Gn0kIiIJpaQgItLPtTcfWQKGHykpiIikCDUfiYhIfJqLRFBSEBHp5442HwV/LCUFEZEUoaQgIiKJfPCakoKISH/XfkezprkQEZE4NR+JiIiaj0RE5Cg9T0FERI6jO5pFRIRENiApKYiI9HPxm9cScCwlBRGRFKHRRyIiotFHIiJy1NHmI3U0i4hIjJqPREREU2eLiMhRA2b0kZktMLONZrbFzG7vpsxHzGydmb1pZr8MMh4RkVSWiOajzKB2bGYhYAkwH6gEVpvZ4+6+rkOZCcCXgXnufsjMhgYVj4hIqhoo01ycD2xx963u3gw8AlzZqcxngCXufgjA3fcFGI+ISEo62qeQ2qOPRgE7O6xXxj7raCIw0cxWmtkqM1vQ1Y7M7EYzW2Nma6qqqgIKV0Skf0v10Uddhd/5IigTmABcBCwCHjCzQcd9yX2pu1e4e0VZWVmfByoi0p8NlOajSmB0h/VyYHcXZf7b3VvcfRuwkWiSEBGRTlJ99NFqYIKZjTezbOA64PFOZX4LvA/AzEqJNidtDTAmEZGUldJTZ7t7BLgFeBJYDzzm7m+a2dfMbGGs2JPAATNbBzwL/LO7HwgqJhGRVJTI5qPAhqQCuPtyYHmnz77aYdmB22IvERHpQvvoo1RvPhIRkT6U6qOPRESkD/TL0Udm9m4z+3RsuczMxgcXloiItIvfutZfrhTM7E7gS0SnpADIAn4eVFAiInK8/vQ8hQ8DC4E6AHffDRQGFZSIiBzlCWw/6m1SaI6NFHIAM8sPLiQREekonhL6S/MR8JiZ/QgYZGafAZ4GfhxcWCIi0lkihqT26j4Fd7/XzOYDR4BJwFfd/Y+BRiYiIkA/u3kt9lyEJ939EkCJQEQk4WI3r/WHaS7cvRWoN7PiwKMREZFu9ZvmI6AReN3M/khsBBKAu98aSFQiIhLXr5qPYv4Qe4mISIIl8ua13nY0PxSb/npi7KON7t4SXFgiItKuJdIGQFYo+JmJepUUzOwi4CFgO9FmrdFm9kl3XxFcaCIiAtDcGk0K2Zn9JCkA3wYudfeNAGY2EXgYODeowEREJKo5dqWQnYArhd4eIas9IQC4+yai8x+JiEjAWlqjvQr9pvkIWGNm/wn8LLZ+PfByMCGJiEhHLf2w+egm4B+AW4n2KawAfhhUUCIiclRzvKM5+OFHvU0KmcB/uPt3IH6Xc05gUYmISFy8o7kf9Sn8CcjtsJ5LdFI8EREJWLyjOQHNR709Qtjda9tXYst5wYQkIiIdtfcpJKKjubdHqDOz2e0rZlYBNAQTkoiIdFTbFMGsf3U0/xPwKzPbTfSO65HAtYFFJSIicRvfqWF8aX7yrxTM7DwzG+7uq4HJwKNABPgfYFvg0YmICNsP1HFmWUFCjtVT2vkR0Bxbngv8C7AEOAQsDTAuERGJqappYmhhYgZ89tR8FHL3g7Hla4Gl7v4b4DdmtjbY0EREpKW1jUP1LZQlKCn0dKUQMrP2xHEx8EyHbb3tjxARkVP0TnUjQMKSQk8n9oeB581sP9HRRn8GMLOzgOqAYxMRSXt/99AaAAbnZSfkeCdMCu7+DTP7EzACeMo9/vyfDGBx0MGJiKS7jXtrAJg5elBCjtdjE5C7r+ris03BhCMiIu2e3bAPgC9fNpmRg3J7KN03Ah30amYLzGyjmW0xs9tPUO5qM/PYTXEiImmvsaWV2x5by5QRRXzyXeMSdtzAkkJs0rwlwGXAVGCRmU3tolwh0dlXXwwqFhGRVNLS2saSZ7dwqL6Fv7/wDMJZoYQdO8grhfOBLe6+1d2bgUeAK7so9+/APUBjgLGIiKSMpSu28v1ntnDF9BF84OzhCT12kElhFLCzw3pl7LM4M5sFjHb33wcYh4hISlm78zBjhuTxg4/OTuhVAgSbFLp6GoTHN5plAN8FPt/jjsxuNLM1ZramqqqqD0MUEelfHvjzVv64bm/CRht1FmRSqARGd1gvB3Z3WC8EpgHPmdl2YA7weFedze6+1N0r3L2irKwswJBFRJLnV2t28vU/rOf9k4fyhUsnJSWGIO9KXg1MMLPxwC7gOuCj7RvdvRoobV83s+eAL7j7mgBjEhHpl9yd3722h5HFYR74RAUZGcE/erMrgV0puHsEuAV4ElgPPObub5rZ18xsYVDHFRFJRV/+r9dZsamKD80cmbSEAAHPX+Tuy4HlnT77ajdlLwoyFhGR/mj34QbufXIj//XKLt43qYzbF0xOajya1E5EJEkeXLmNe5/cSGOkjatmj+Luv5mOWfKuEkBJQUQk4eqaIvxoxVbu+9NmhhXl8Psb5zK+ND/ZYQFKCiIigXJ39h5pYu+RRqpqmthSVcsDf97K/tpmpowo4vuLZvWbhABKCiIigdm2v447H3+TFZuOvb9qxuhBLP1EBbPHDE5SZN1TUhAR6WOb9tbw8Etv87MXdpCRYXzh0olMGVFEaUEOpYU5jCgKJ3WE0YkoKYiInIbWNmfzvhq2VtWx90gjW6vq+NmqHQB8cPoIvnrFVIYVhZMcZe8pKYiI9IK7U1XbxMZ3atj4Tg2b9tawcW8tm/fWUN/cGi+XFTLOHz+EOz80lbNHFicx4lOjpCAi0klrm1PbGOFIYwuH61v42art/HHdXg7Vt8TLlBZkM3FYIR+pGM2M0cVMGlbE8OIwg/Oykj6s9HQoKYhIWjtQ28SqrQfZfqCOXYcbeGb9Pt45cvxM/h84exhzzyhh4vBCJg4rpLQgJwnRBk9JQUQGPHfnhbcO8M6RRmqbItQ0Rl8vbD3AqzsPx8sVhTMZU5LHVbNHUVqQQ1FuFkXhTM4cWsCZZQVJrEHiKCmISEppirRS39RKbVOE+uboe0NzK40trTRGWmlqaaMx0kpjSxuNLa00tbTyxu4jPBN73nG77FAG5YNz+cKlE5l3VimThheSl61Tov4CIpJ0jS2t7DvSxNrKw2zeWxM9wcdO6o2R2Mk90sa2/bXsPNhw0vsfURyOT0c9tCiHgpzMhD+8JlUoKYhIYNranJqmCDWNLRxpiL7XNEaoaYquVze08PymKl7eceiY7+VmhQhnZZCTGX0PZ4XIyQoxaVghHzl3NAXhTPJzMsnPziQ/J0RedubRcpnR93BmiJysDHIyM1K64zfRlBRE5DiR1jbePljP2wfraWxppbnVibS2EWl1Wtpi761ttMQ+b2mLrm/eW8vOg/UdTv6RHo91Rmk+t77/LEYPyWPkoFzOHz+ErFCQz/+SE1FSEBlg2tqctw/WU93QQl1ThNrYqz7W7t7Q3EpDS/R17HobjbHlXYcbOFjXfFLHzQoZg/KymTV6EEW5WRSGMykMRztqi8Id1nOj79H1THIy1YzTnygpiARoX00jJfk5hLqY0qCtzWmMtFLfHD0x5+dkHjPG3d2pbYrQHGmjubWNlojT3NpKc8Sj661tNLW0sae6ge0H6th+oJ4dB+rYVlVHXYebqboSyjDyskKEs0PkZsVeseWywhzOKMtn3lmlnFGaT35OJlkhIzMjg6zMDLIyjMxQBpkhIysj+p6ZYWqiGSCUFCRttLUdPZk2R9o4WNfMnupG6ptbY00hR7c1x5pHmiNt1DVFONIYaxdvPNouXtsYoSCcydDCHIYW5lBWmEN1QwuvVVZzqL6ZIw0RGlpaMYPpo4qjJ//YL/P25c7yskOUD86lfHAeuw41sHFvTa/qFsowygfnMrYkn3PHDObskcUMyc+mIJxJQU57+/vRJKDmGemOkoKknKZIK4frW9i+v46Ddc3UNbfS0Bxtv35z1xF2Vzewv7aJhuajJ/mW1jYibX5Kx8vOzKAo1gxSGM6kKDeLEcVh8rMzqWmMUFXbxMtvH2LfkSaaIm0Myc9m/pRhFOVm8uDK7UwYVkhxXjYjikPkZUd/kUffM8mLLYezQtQ2Rqg81MCuw/VUHmogLyfEFxdMoiAnk6xQBtmh6C/17FAG2ZlGdihEVsgYVhRm1OBcneilTygpSL/h7jTFhh/WN7dyoLaZtTsPsXFvDe9UN7F+zxH210ZPvN0ZVpTDxGGFjB2SR15OZuwEmkFWyMgKZRw9uYaMwfnZjByUS152KPZZe9mMY76X2cuTrXt0pE04M0R2ZvQ7d3xwap/8bUQSRUlBTktzJNqmXdMY7cisb46weW8ts8cOZtSgXKobWjhc38zhhhZ2Hqxnwzs1HKht4nBDS7yDs71Nvb45Qlc/5otzsxheFObcsYMZURyO32U6piSfoYU55GdnkpcTIj82LDFZbdtmRlE4KynHFukrSgoCHP2Vu+dwI3uqG3inupHd1Y3srW6kvqWV5khrvMOzqSX6vu9IE3trGvGTaJUpK8xhWFEOg3KzKSvIiTen5GZldliONqkMystmfGk+E4cVqBNTJEGUFAYYd+dQfQv7ahrZd6SJfTVHm13aO0ebItG7Q5sjbTTFXvXNkWOm/wUwg5L8HApyos0hObFmkexQBvk5mUwYWkj54FxGDc6lODcr1j6eibvz+q5qcjJDDMrLojg3+hqcn83I4rBO8CL9mJJCCqppbGHvkSYO1zfz17cPsfGdWmoaW9i2v47tB+poaT32p3s4K4NhRWEKYyNRBuVlk5MZbTOPnuwzyM3KZHhxDsOLcxlRHGZEcZihheF42/jJqhg3pC+qKiIJpqSQImoaW/jBs1v4w2t7qDx07NwvI4rDFIWjv8avO28M40vzGVqUw9DCMMOKchhRnHvKJ3cRSS9KCv1UpLWNrfvreH5jFSs2V/HStoM0RdqYe0YJi84fQ/ngXAblZXNGaT6jh+QlO1wRGSCUFJKsrc3ZvK+WPdUN1DZFeGtfHc9s2MurldXxMhOGFvDRC8Zw2bQRnD9ezTIiEhwlhQBFWtt4Y/cRdhyo40hjhIqxg9l9uIE3dx9h4zs17K9t4sVtB4/73rRRRXz2wjMYNSiXOWeUMHFYYRKiF5F0pKRwGtranNrm6DDOdXuq2bKvlrf21fH2wXr21TRxsK6py3H3AGNL8hhWGOaSKcOYXl7MvLNKKQxnMigvi6GF4cRWREQkRknhFFQ3tPCvv32DJ17fc8zUCaEMY2xJHmOH5DG9vJihhTlMHF7I5OGF1De38tK2g4wZkse7ziqlIEd/ehHpf3Rm6oV3qhvZfqCOqpomXt5xiF+t2Ul9Sysfu2AsY0vyKApnMWP0IMaX5p9wlM/08kEJjFpE5OQpKZzAqzsP8+M/b2X563vizUDZmRlcPHkon3nvGcweMzi5AYqI9LFAk4KZLQD+AwgBD7j7Nzttvw34OyACVAF/6+47goypJzsP1vPD595i3e5qXq2spiicySffNY6LJw9jaFEOowblkq+mHxEZoAI7u5lZCFgCzAcqgdVm9ri7r+tQ7BWgwt3rzewm4B7g2qBiOpEDtU388sW3WbpiK02RNmaOHsQdl09h0QVj1P4vImkjyLPd+cAWd98KYGaPAFcC8aTg7s92KL8K+FiA8XTrwZXb+OYTG2iKtPG+SWV85YqpnFFWkIxQRESSKsikMArY2WG9ErjgBOVvAJ4IMJ7juDtLV2zl7v/ZwDnlg/jW1dN1T4CIpLUgk0JXU2F2OWrfzD4GVAAXdrP9RuBGgDFjxvRJcI0trdzyy1d4ev1e3jepjO9/dLaaiUQk7QV5FqwERndYLwd2dy5kZpcAdwAXuntTVzty96XAUoCKiopTe6ZiB61tzmd+uoY/b97PFy6dyN9feGavn64lIjKQBXkmXA1MMLPxZpYNXAc83rGAmc0CfgQsdPd9AcZyjN+/tps/b97PZ997Bre8f4ISgohITGBnQ3ePALcATwLrgcfc/U0z+5qZLYwV+xZQAPzKzNaa2ePd7K5P/WTldsaX5vOlBZMTcTgRkZQRaCO6uy8Hlnf67Ksdli8J8vhd+fZTG3l152H+5fLJZGToCWAiIh2lXbvJo6ujA6KureibDmsRkYEkrZLCzoP17K9t4uaLzqQ4LyvZ4YiI9DtplRRe2HqANocPzxqV7FBERPqltEoKf91xiMJwJmfqbmURkS6lVVJ4q6qWqSOK1MEsItKNtEoKe6obGVGsp5qJiHQnbZJCW5uz70gTw5QURES6lTZJ4WB9M82tbQwvUlIQEelO+iSFumYASgpykhyJiEj/lTZJoaG5FYD87FCSIxER6b/SJinUx5JCbpaSgohId9ImKTS0RADI1ZWCiEi30icpNLcBkJetB+mIiHQnbZJCS2s0KWSFdOOaiEh30iYpeOxJoGZKCiIi3UmfpBB7iKdmuBAR6V7aJIW2WFIwlBVERLqTNknBvb35KMmBiIj0Y+mTFGLvSgoiIt1Ln6Tg6mgWEelJGiWF6LtSgohI99InKcTeM3SlICLSrbRJCm3qaBYR6VHaJAU1H4mI9Cx9kkLsXR3NIiLdS5+koOYjEZEepVFSiL4rJ4iIdC+NkkI0K2j0kYhI99ImKcTnPlJOEBHpVtokhXhHsxqQRES6lT5Job2jOW1qLCJy8gI9RZrZAjPbaGZbzOz2LrbnmNmjse0vmtm4oGJRR7OISM8CSwpmFgKWAJcBU4FFZja1U7EbgEPufhbwXeDuoOLRk9dERHoW5JXC+cAWd9/q7s3AI8CVncpcCTwUW/41cLEFdNbWk9dERHoWZFIYBezssF4Z+6zLMu4eAaqBks47MrMbzWyNma2pqqo6pWDGl+Zz+TnDCSkriIh0KzPAfXd19vVTKIO7LwWWAlRUVBy3vTcuPXs4l549/FS+KiKSNoK8UqgERndYLwd2d1fGzDKBYuBggDGJiMgJBJkUVgMTzGy8mWUD1wGPdyrzOPDJ2PLVwDPePnZUREQSLrBdiDceAAAF3klEQVTmI3ePmNktwJNACPiJu79pZl8D1rj748B/Aj8zsy1ErxCuCyoeERHpWZB9Crj7cmB5p8++2mG5EbgmyBhERKT3dH+viIjEKSmIiEickoKIiMQpKYiISJyl2ghQM6sCdpzi10uB/X0YTipQndOD6pweTqfOY929rKdCKZcUToeZrXH3imTHkUiqc3pQndNDIuqs5iMREYlTUhARkbh0SwpLkx1AEqjO6UF1Tg+B1zmt+hREROTE0u1KQURETmBAJoX+9GzoROlFnW8zs3Vm9pqZ/cnMxiYjzr7UU507lLvazNzMUn6kSm/qbGYfif1bv2lmv0x0jH2tF/9tjzGzZ83sldh/35cnI86+YmY/MbN9ZvZGN9vNzO6L/T1eM7PZfRqAuw+oF9EZWd8CzgCygVeBqZ3K3AzcH1u+Dng02XEnoM7vA/JiyzelQ51j5QqBFcAqoCLZcSfg33kC8AowOLY+NNlxJ6DOS4GbYstTge3Jjvs06/xeYDbwRjfbLweeIPqQsjnAi315/IF4pdCvng2dID3W2d2fdff62Ooqog89SmW9+XcG+HfgHqAxkcEFpDd1/gywxN0PAbj7vgTH2Nd6U2cHimLLxRz/MK+U4u4rOPHDxq4EfupRq4BBZjair44/EJNCnz0bOoX0ps4d3UD0l0Yq67HOZjYLGO3uv09kYAHqzb/zRGCima00s1VmtiBh0QWjN3W+C/iYmVUSnap/cWJCS5qT/f/9pAT6PIUk6bNnQ6eQXtfHzD4GVAAXBhpR8E5YZzPLAL4LfCpRASVAb/6dM4k2IV1E9Grwz2Y2zd0PBxxbUHpT50XAMnf/tpnNJfrgrmnu3hZ8eEkR6PlrIF4ppOOzoXtTZ8zsEuAOYKG7NyUotqD0VOdCYBrwnJltJ9r2+niKdzb39r/t/3b3FnffBmwkmiRSVW/qfAPwGIC7vwCEic4RNFD16v/3UzUQk0I6Phu6xzrHmlJ+RDQhpHo7M/RQZ3evdvdSdx/n7uOI9qMsdPc1yQm3T/Tmv+3fEh1UgJmVEm1O2prQKPtWb+r8NnAxgJlNIZoUqhIaZWI9DnwiNgppDlDt7nv6aucDrvnI0/DZ0L2s87eAAuBXsT71t919YdKCPk29rPOA0ss6PwlcambrgFbgn939QPKiPj29rPPngR+b2eeINqN8KpV/5JnZw0Sb/0pj/SR3AlkA7n4/0X6Ty4EtQD3w6T49fgr/7UREpI8NxOYjERE5RUoKIiISp6QgIiJxSgoiIhKnpCAiInFKCpI2zKzEzNbGXu+Y2a7Y8uHYEM6+Pt5FZnZSU2yY2XNd3WBnZp8ysx/0XXQiXVNSkLTh7gfcfaa7zwTuB74bW54J9DglQuzud5EBTUlBJCpkZj+OPYPgKTPLhfgv9/9tZs8D/2hmZWb2GzNbHXvNi5W7sMNVyCtmVhjbb4GZ/drMNpjZL9pn4zWzi2PlXo/Nn5/TOSAz+7SZbYode16C/g6S5pQURKImEJ1y+mzgMPA3HbYNcvcL3f3bwH8QvcI4L1bmgViZLwD/ELvyeA/QEPt8FvBPROf5PwOYZ2ZhYBlwrbufQ3RmgZs6BhObCvnfiCaD+bHviwROSUEkapu7r40tvwyM67Dt0Q7LlwA/MLO1ROegKYpdFawEvmNmtxJNIpFY+ZfcvTI2Y+fa2H4nxY63KVbmIaIPVunoAuA5d6+KPUfgUUQSQG2kIlEdZ41tBXI7rNd1WM4A5rp7A8f6ppn9geicNKtiM9J2td9Mup76uCuag0YSTlcKIifnKeCW9hUzmxl7P9PdX3f3u4E1wOQT7GMDMM7Mzoqtfxx4vlOZF4GLYiOmsoBr+qoCIieipCBycm4FKmIPTF8H/H3s838yszfM7FWi/QndPtnO3RuJzmz5KzN7nejIp/s7ldlD9IliLwBPA3/t64qIdEWzpIqISJyuFEREJE5JQURE4pQUREQkTklBRETilBRERCROSUFEROKUFEREJE5JQURE4v4/cGj0ATjgTWwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56674   196]\n",
      " [   12    79]]\n",
      "The highest fraud likelihood measured was 1.0.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(train_x)\n",
    "print(model.summary())\n",
    "model, history = train_model(model, train_x, train_y, epochs = 40, batch_size=64)\n",
    "\n",
    "get_report(model, history, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, you will likely see a very high accuracy, decent recall, bad F1 score and terrible precision.  This is fine!  Keep in mind we've told the network to treat a false negative much harsher than a false positive in order to balance the training weight updates.  This only prevents the network from having its weight updates dominated by the majority class.  It does not prevent the model from being wrong!  Especially considering the fact that we have 578 genuine transactions for every fraudulent one, it's highly unlikely to expect the model to have the same frequency of false negatives as false positives.\n",
    "\n",
    "A helpful metric that can give more insight into this is the specificity score (sister metric of recall), which represents the fraction of true negatives that were predicted negative.  For this case, since our confusion matrix result was:\n",
    "\n",
    "$\\begin{vmatrix}\n",
    "56674 & 196\\\\ \n",
    "12 & 79\n",
    "\\end{vmatrix}$\n",
    "\n",
    "The specificity score is 0.9966, meaning only 0.34% of all genuine transactions were flagged as fraudulent by our model.  In the real world, this would be manageable over a two day period (the rough timeframe of this dataset) for a team of investigators.  A handful of cases would be resolved fairly quickly (and possible automatically and/or by the hand of the customer), so one could expect far fewer than 100 manual investigations per day.\n",
    "\n",
    "While this method seems to work fine, let's take a look at a more traditional approach next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 787\n",
      "Test examples: 197\n",
      "[[103   4]\n",
      " [  7  83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       107\n",
      "           1       0.95      0.92      0.94        90\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       197\n",
      "   macro avg       0.95      0.94      0.94       197\n",
      "weighted avg       0.94      0.94      0.94       197\n",
      "\n",
      "0.9441624365482234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "train_x, train_y, test_x, test_y = split_data(df_u, 0.8)\n",
    "\n",
    "# train model\n",
    "rf = RandomForestClassifier(n_estimators=12).fit(train_x, train_y)\n",
    "\n",
    "# predict on test set\n",
    "rf_pred = rf.predict(test_x)\n",
    "\n",
    "print(confusion_matrix(test_y,rf_pred))\n",
    "print(classification_report(test_y,rf_pred))\n",
    "print(accuracy_score(test_y,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this decision tree model, we are using an undersampling of our original dataset (with standardization applied) in order to balance the classes.  Decision trees can have a tendency to ignore tiny clusters of data in favor of more generalizing splits (essentially if-else blocks).  This can hurt a very unbalanced dataset because those tiny clusters could have been fraudulent charges and blending them with their neighboring cluster of data could prevent the model from working at all.\n",
    "\n",
    "This tree had a decent confusion matrix result:\n",
    "\n",
    "$\\begin{vmatrix}\n",
    "103 & 4\\\\ \n",
    "7 & 83\n",
    "\\end{vmatrix}$\n",
    "\n",
    "Remember, these results are on the test data from our undersampled dataset, so the total support is much smaller.\n",
    "\n",
    "In the end, both models work relatively well - recall above 90% and transaction evaluation time is only a fraction of a second.  Both models would benefit from having more data.  Unfortunately it seems to be a catch 22 - if you want to prevent fraudulent charges, you need to record more fraudulent charges in order to know how to prevent them!  Nevertheless, having a robust fraud detection model can only improve existing systems.  Even with a lower alert threshold (below 50%), you can attain much better results than you could by using \"hunch\" logic flows.\n",
    "\n",
    "\n",
    "If you found this material interesting, I highly recommend you check out some of the highly regarded, publicly available Kaggle kernels for this topic: https://www.kaggle.com/mlg-ulb/creditcardfraud/kernels?sortBy=voteCount&group=everyone&pageSize=20&datasetId=310\n",
    "\n",
    "There are many great ideas present in their work, and they certainly surpass the level of expertise and knowledge present in this notebook!\n",
    "\n",
    "I also recommend you check out the original thesis by Andrea Dal Pozzolo, whom without we would not have this dataset:\n",
    "https://dalpozz.github.io/static/pdf/Dalpozzolo2015PhD.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've made it to the end of this notebook, I would like to say:\n",
    "\n",
    "Thanks very much for reading!  I hope you enjoyed this notebook and found some useful tidbits and factoids!\n",
    "\n",
    "If you are interested in any of my other work, feel free to check out my GitHub here:  https://github.com/AlexBorger/DataProjects\n",
    "\n",
    "Or if you wanted to know more about my experience, please visit my LinkedIn page:\n",
    "https://www.linkedin.com/in/alex-borger/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
